{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello, TensorFlow!'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "hello = tf.constant(\"Hello, TensorFlow!\")\n",
    "\n",
    "sess = tf.Session() #세션 만들기\n",
    "print(sess.run(hello))\n",
    "#hello를 실행, 실행 후 b = byte string 의미\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sess.run(node1, node2) :  [3.0, 4.0]\n",
      "sess.run(node3):  7.0\n"
     ]
    }
   ],
   "source": [
    "#그래프 제작(Computational Graph)\n",
    "#노드 만들기\n",
    "node1 = tf.constant(3.0, tf.float32)\n",
    "node2 = tf.constant(4.0)\n",
    "node3 = tf.add(node1, node2) #더하기 노드 만들기\n",
    "\n",
    "#세션 만들기\n",
    "sess = tf.Session()\n",
    "print(\"sess.run(node1, node2) : \", sess.run([node1, node2]))\n",
    "print(\"sess.run(node3): \", sess.run(node3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.5\n",
      "[3. 7.]\n"
     ]
    }
   ],
   "source": [
    "#Placeholder\n",
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "adder_node = a + b\n",
    "print(sess.run(adder_node, feed_dict ={a: 3, b: 4.5}))\n",
    "print(sess.run(adder_node, feed_dict ={a: [1,3], b: [2,4]})) #각 요소끼리 더해짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 13.637481 [0.30027854] [-2.2489915]\n",
      "20 0.46486315 [1.5470967] [-1.6092856]\n",
      "40 0.31411257 [1.636975] [-1.4828069]\n",
      "60 0.2843022 [1.6180459] [-1.4082787]\n",
      "80 0.2581989 [1.5900481] [-1.3416337]\n",
      "100 0.23450007 [1.5624177] [-1.2785376]\n",
      "120 0.2129768 [1.5359955] [-1.218447]\n",
      "140 0.19342892 [1.5108068] [-1.1611841]\n",
      "160 0.17567539 [1.4868008] [-1.1066128]\n",
      "180 0.15955122 [1.4639231] [-1.0546061]\n",
      "200 0.14490692 [1.4421203] [-1.0050436]\n",
      "220 0.13160676 [1.4213423] [-0.95781016]\n",
      "240 0.11952734 [1.4015406] [-0.91279656]\n",
      "260 0.10855666 [1.3826698] [-0.8698985]\n",
      "280 0.09859293 [1.3646859] [-0.8290165]\n",
      "300 0.08954366 [1.3475469] [-0.79005575]\n",
      "320 0.081324995 [1.3312135] [-0.75292605]\n",
      "340 0.0738607 [1.3156477] [-0.7175414]\n",
      "360 0.06708149 [1.3008134] [-0.6838198]\n",
      "380 0.0609245 [1.2866764] [-0.65168285]\n",
      "400 0.055332605 [1.2732037] [-0.62105626]\n",
      "420 0.050254006 [1.2603642] [-0.59186894]\n",
      "440 0.04564147 [1.2481279] [-0.5640533]\n",
      "460 0.04145233 [1.2364669] [-0.53754485]\n",
      "480 0.037647653 [1.225354] [-0.51228213]\n",
      "500 0.03419217 [1.214763] [-0.48820677]\n",
      "520 0.031053923 [1.2046701] [-0.46526286]\n",
      "540 0.02820365 [1.1950512] [-0.44339722]\n",
      "560 0.025615005 [1.1858845] [-0.4225592]\n",
      "580 0.023263955 [1.1771486] [-0.40270045]\n",
      "600 0.021128677 [1.1688231] [-0.38377494]\n",
      "620 0.019189397 [1.160889] [-0.36573884]\n",
      "640 0.017428115 [1.153328] [-0.34855032]\n",
      "660 0.015828492 [1.146122] [-0.33216974]\n",
      "680 0.014375694 [1.1392548] [-0.31655893]\n",
      "700 0.0130562335 [1.1327102] [-0.30168185]\n",
      "720 0.011857863 [1.1264734] [-0.28750387]\n",
      "740 0.010769508 [1.1205297] [-0.27399224]\n",
      "760 0.00978103 [1.1148652] [-0.26111558]\n",
      "780 0.0088832835 [1.1094669] [-0.24884407]\n",
      "800 0.008067959 [1.1043224] [-0.23714933]\n",
      "820 0.007327424 [1.0994195] [-0.22600406]\n",
      "840 0.006654902 [1.0947472] [-0.21538268]\n",
      "860 0.006044086 [1.0902945] [-0.2052605]\n",
      "880 0.0054893307 [1.086051] [-0.19561405]\n",
      "900 0.004985496 [1.0820067] [-0.18642092]\n",
      "920 0.0045278943 [1.0781527] [-0.17765966]\n",
      "940 0.0041123093 [1.0744798] [-0.16931027]\n",
      "960 0.0037348687 [1.0709796] [-0.16135335]\n",
      "980 0.0033920743 [1.0676438] [-0.1537703]\n",
      "1000 0.0030807238 [1.0644648] [-0.14654365]\n",
      "1020 0.0027979647 [1.0614352] [-0.13965668]\n",
      "1040 0.0025411604 [1.058548] [-0.13309334]\n",
      "1060 0.0023079189 [1.0557964] [-0.12683839]\n",
      "1080 0.0020960926 [1.0531743] [-0.1208775]\n",
      "1100 0.001903709 [1.0506754] [-0.11519676]\n",
      "1120 0.0017289817 [1.0482937] [-0.10978297]\n",
      "1140 0.0015702847 [1.0460241] [-0.10462358]\n",
      "1160 0.0014261595 [1.043861] [-0.09970663]\n",
      "1180 0.0012952639 [1.0418] [-0.09502085]\n",
      "1200 0.0011763794 [1.0398355] [-0.09055526]\n",
      "1220 0.0010684029 [1.0379633] [-0.08629946]\n",
      "1240 0.00097033876 [1.0361791] [-0.08224364]\n",
      "1260 0.0008812791 [1.0344788] [-0.07837843]\n",
      "1280 0.000800393 [1.0328585] [-0.07469493]\n",
      "1300 0.00072692585 [1.0313141] [-0.07118455]\n",
      "1320 0.0006602083 [1.0298425] [-0.06783916]\n",
      "1340 0.000599612 [1.0284401] [-0.06465096]\n",
      "1360 0.000544578 [1.0271035] [-0.06161259]\n",
      "1380 0.00049459405 [1.0258298] [-0.05871705]\n",
      "1400 0.00044920004 [1.0246159] [-0.05595761]\n",
      "1420 0.00040797214 [1.0234591] [-0.05332787]\n",
      "1440 0.00037052517 [1.0223566] [-0.05082168]\n",
      "1460 0.00033651633 [1.0213059] [-0.04843333]\n",
      "1480 0.00030563204 [1.0203047] [-0.04615716]\n",
      "1500 0.00027757694 [1.01935] [-0.04398781]\n",
      "1520 0.00025209817 [1.0184407] [-0.04192043]\n",
      "1540 0.00022895739 [1.0175742] [-0.03995025]\n",
      "1560 0.00020794339 [1.0167483] [-0.03807275]\n",
      "1580 0.00018885895 [1.0159612] [-0.03628347]\n",
      "1600 0.00017152431 [1.0152111] [-0.03457829]\n",
      "1620 0.00015578083 [1.0144962] [-0.03295325]\n",
      "1640 0.00014148372 [1.0138149] [-0.03140456]\n",
      "1660 0.00012849703 [1.0131656] [-0.02992861]\n",
      "1680 0.00011670235 [1.0125469] [-0.02852206]\n",
      "1700 0.00010599213 [1.0119573] [-0.02718165]\n",
      "1720 9.626238e-05 [1.0113953] [-0.0259042]\n",
      "1740 8.742767e-05 [1.0108597] [-0.02468682]\n",
      "1760 7.940384e-05 [1.0103495] [-0.02352669]\n",
      "1780 7.211581e-05 [1.0098631] [-0.02242105]\n",
      "1800 6.549725e-05 [1.0093995] [-0.02136732]\n",
      "1820 5.9484824e-05 [1.0089577] [-0.02036313]\n",
      "1840 5.4025568e-05 [1.0085368] [-0.01940614]\n",
      "1860 4.906642e-05 [1.0081357] [-0.01849413]\n",
      "1880 4.45623e-05 [1.0077533] [-0.01762498]\n",
      "1900 4.0472933e-05 [1.007389] [-0.01679666]\n",
      "1920 3.6758825e-05 [1.0070417] [-0.01600729]\n",
      "1940 3.338497e-05 [1.0067106] [-0.01525502]\n",
      "1960 3.032054e-05 [1.0063953] [-0.0145381]\n",
      "1980 2.7537506e-05 [1.0060948] [-0.01385484]\n",
      "2000 2.5010324e-05 [1.0058084] [-0.01320373]\n"
     ]
    }
   ],
   "source": [
    "#H(x) = Wx+b 가설 세우기\n",
    "#학습할 데이터\n",
    "x_train = [1,2,3]\n",
    "y_train = [1,2,3]\n",
    "#Variable. 텐서플로가 자체적으로 변경시키는 값. 변수. trainable.\n",
    "#여기서 W,b라는 Variable을 정의했다고 생각하면 된다\n",
    "W = tf.Variable(tf.random_normal([1]), name = 'weight') #rank = 1인 array\n",
    "b = tf.Variable(tf.random_normal([1]), name = 'bias') \n",
    "hypothesis = x_train * W + b    \n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y_train))\n",
    "#reduce_mean -> 값이 주어졌을 때 평균을 내준다\n",
    "#Minimize, 그래프 구현\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "train = optimizer.minimize(cost) #그래프 이름을 train이라고 한 셈\n",
    "#session\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(2001):\n",
    "    sess.run(train)\n",
    "    if step % 20 == 0 : #step을 20번에 한 번씩 출력해라\n",
    "        print(step, sess.run(cost), sess.run(W), sess.run(b))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.9144096 [2.1111307] [-2.04215]\n",
      "20 0.5911317 [1.9059815] [-2.0134504]\n",
      "40 0.5347051 [1.8488419] [-1.9252315]\n",
      "60 0.4856082 [1.8075627] [-1.8353627]\n",
      "80 0.4410369 [1.7694783] [-1.7491653]\n",
      "100 0.40055683 [1.7333031] [-1.6669666]\n",
      "120 0.36379206 [1.6988393] [-1.5886258]\n",
      "140 0.33040175 [1.6659962] [-1.5139662]\n",
      "160 0.30007607 [1.6346968] [-1.4428152]\n",
      "180 0.27253386 [1.6048684] [-1.3750082]\n",
      "200 0.24751973 [1.5764419] [-1.310388]\n",
      "220 0.22480132 [1.5493512] [-1.2488045]\n",
      "240 0.20416804 [1.5235337] [-1.1901152]\n",
      "260 0.18542892 [1.4989296] [-1.1341845]\n",
      "280 0.16840945 [1.4754817] [-1.0808818]\n",
      "300 0.1529522 [1.453136] [-1.0300845]\n",
      "320 0.13891365 [1.4318403] [-0.98167443]\n",
      "340 0.12616357 [1.4115454] [-0.9355393]\n",
      "360 0.11458382 [1.3922043] [-0.8915725]\n",
      "380 0.10406681 [1.373772] [-0.8496717]\n",
      "400 0.09451518 [1.3562062] [-0.80974025]\n",
      "420 0.08584016 [1.3394657] [-0.7716855]\n",
      "440 0.07796138 [1.323512] [-0.735419]\n",
      "460 0.070805795 [1.3083082] [-0.7008569]\n",
      "480 0.064306945 [1.293819] [-0.6679193]\n",
      "500 0.058404624 [1.2800105] [-0.6365296]\n",
      "520 0.05304399 [1.2668511] [-0.60661507]\n",
      "540 0.048175424 [1.25431] [-0.5781064]\n",
      "560 0.043753702 [1.2423583] [-0.5509376]\n",
      "580 0.039737795 [1.2309684] [-0.52504545]\n",
      "600 0.036090508 [1.2201138] [-0.5003702]\n",
      "620 0.03277795 [1.2097691] [-0.47685468]\n",
      "640 0.029769482 [1.1999108] [-0.45444423]\n",
      "660 0.027037123 [1.1905158] [-0.43308702]\n",
      "680 0.024555514 [1.1815621] [-0.41273353]\n",
      "700 0.022301726 [1.1730293] [-0.39333656]\n",
      "720 0.02025479 [1.1648978] [-0.37485114]\n",
      "740 0.018395703 [1.157148] [-0.35723448]\n",
      "760 0.016707273 [1.1497626] [-0.34044576]\n",
      "780 0.01517384 [1.1427245] [-0.3244461]\n",
      "800 0.013781113 [1.136017] [-0.30919835]\n",
      "820 0.012516231 [1.1296245] [-0.29466715]\n",
      "840 0.01136743 [1.1235328] [-0.2808188]\n",
      "860 0.01032409 [1.1177272] [-0.2676214]\n",
      "880 0.009376512 [1.1121945] [-0.25504428]\n",
      "900 0.008515898 [1.1069218] [-0.24305822]\n",
      "920 0.007734276 [1.1018966] [-0.2316354]\n",
      "940 0.0070243925 [1.097108] [-0.22074933]\n",
      "960 0.0063796765 [1.0925443] [-0.210375]\n",
      "980 0.005794126 [1.0881952] [-0.20048822]\n",
      "1000 0.0052623264 [1.0840504] [-0.19106606]\n",
      "1020 0.004779309 [1.0800999] [-0.18208654]\n",
      "1040 0.0043406426 [1.0763358] [-0.17352909]\n",
      "1060 0.0039422405 [1.0727482] [-0.16537388]\n",
      "1080 0.0035804126 [1.0693294] [-0.15760191]\n",
      "1100 0.0032517968 [1.0660712] [-0.15019523]\n",
      "1120 0.0029533256 [1.0629661] [-0.14313662]\n",
      "1140 0.0026822581 [1.0600066] [-0.13640966]\n",
      "1160 0.0024360665 [1.0571866] [-0.12999882]\n",
      "1180 0.0022124725 [1.0544991] [-0.12388937]\n",
      "1200 0.0020094092 [1.0519379] [-0.11806702]\n",
      "1220 0.0018249722 [1.049497] [-0.11251838]\n",
      "1240 0.0016574735 [1.0471709] [-0.10723045]\n",
      "1260 0.0015053409 [1.0449541] [-0.10219103]\n",
      "1280 0.0013671778 [1.0428414] [-0.09738845]\n",
      "1300 0.0012416994 [1.0408282] [-0.09281164]\n",
      "1320 0.0011277265 [1.0389092] [-0.08844978]\n",
      "1340 0.0010242168 [1.0370805] [-0.08429291]\n",
      "1360 0.00093021034 [1.0353379] [-0.08033142]\n",
      "1380 0.0008448339 [1.0336772] [-0.07655615]\n",
      "1400 0.000767289 [1.0320945] [-0.07295828]\n",
      "1420 0.00069686404 [1.0305862] [-0.06952951]\n",
      "1440 0.0006329045 [1.0291487] [-0.06626192]\n",
      "1460 0.0005748133 [1.0277789] [-0.06314783]\n",
      "1480 0.0005220546 [1.0264733] [-0.06018008]\n",
      "1500 0.00047413597 [1.0252292] [-0.05735181]\n",
      "1520 0.00043062153 [1.0240436] [-0.05465652]\n",
      "1540 0.00039109527 [1.0229136] [-0.05208787]\n",
      "1560 0.00035520014 [1.0218368] [-0.04963992]\n",
      "1580 0.00032259594 [1.0208104] [-0.04730712]\n",
      "1600 0.0002929871 [1.019832] [-0.04508369]\n",
      "1620 0.00026609263 [1.0189] [-0.04296473]\n",
      "1640 0.00024166681 [1.0180119] [-0.04094546]\n",
      "1660 0.00021948853 [1.0171654] [-0.03902119]\n",
      "1680 0.0001993429 [1.0163587] [-0.03718734]\n",
      "1700 0.00018104703 [1.01559] [-0.03543966]\n",
      "1720 0.00016442924 [1.0148573] [-0.03377413]\n",
      "1740 0.00014933741 [1.0141591] [-0.03218687]\n",
      "1760 0.00013563008 [1.0134938] [-0.03067425]\n",
      "1780 0.00012318294 [1.0128595] [-0.02923268]\n",
      "1800 0.00011187595 [1.0122552] [-0.02785884]\n",
      "1820 0.000101608166 [1.0116792] [-0.02654959]\n",
      "1840 9.228167e-05 [1.0111303] [-0.02530189]\n",
      "1860 8.381169e-05 [1.0106074] [-0.02411282]\n",
      "1880 7.612147e-05 [1.010109] [-0.02297974]\n",
      "1900 6.913342e-05 [1.0096337] [-0.02189981]\n",
      "1920 6.2787956e-05 [1.009181] [-0.02087059]\n",
      "1940 5.7025532e-05 [1.0087496] [-0.01988979]\n",
      "1960 5.1791907e-05 [1.0083383] [-0.01895507]\n",
      "1980 4.703815e-05 [1.0079465] [-0.01806425]\n",
      "2000 4.2721713e-05 [1.0075731] [-0.01721533]\n",
      "[0.9903578 1.9979309 3.0055041]\n",
      "[0.9903578 1.9979309 3.0055041]\n",
      "[0.9903578 1.9979309 3.0055041]\n"
     ]
    }
   ],
   "source": [
    "#placeholder를 이용한 linear Regression\n",
    "#학습할 데이터\n",
    "x_train = [1,2,3]\n",
    "y_train = [1,2,3]\n",
    "#placeholder 이용\n",
    "X= tf.placeholder(tf.float32)\n",
    "Y= tf.placeholder(tf.float32)\n",
    "hypothesis = x_train * W + b    \n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y_train))\n",
    "#reduce_mean -> 값이 주어졌을 때 평균을 내준다\n",
    "#Minimize, 그래프 구현\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "train = optimizer.minimize(cost) #그래프 이름을 train이라고 한 셈\n",
    "#session\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(2001) :\n",
    "    cost_val, W_val, b_val, _ = sess.run([cost, W, b, train],\n",
    "            feed_dict = {X: [1,2,3], Y: [1,2,3]})\n",
    "    #모델을 만들어 놓은 다음에 학습 데이터를 넣을 수 있다\n",
    "    if step % 20 == 0:\n",
    "        print(step, cost_val, W_val, b_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "0 55.07727 [-0.7777394] [1.3527043]\n",
      "20 0.077761956 [0.81371146] [1.7447127]\n",
      "40 0.06693038 [0.832574] [1.7043351]\n",
      "60 0.058450855 [0.843569] [1.6647651]\n",
      "80 0.051045526 [0.8538139] [1.6277784]\n",
      "100 0.044578508 [0.8633876] [1.5932139]\n",
      "120 0.03893078 [0.8723345] [1.5609131]\n",
      "140 0.033998553 [0.88069534] [1.5307274]\n",
      "160 0.02969111 [0.8885088] [1.5025185]\n",
      "180 0.02592951 [0.89581037] [1.4761574]\n",
      "200 0.022644466 [0.90263385] [1.4515227]\n",
      "220 0.019775568 [0.9090104] [1.4285014]\n",
      "240 0.017270181 [0.9149693] [1.4069877]\n",
      "260 0.01508216 [0.92053807] [1.3868827]\n",
      "280 0.01317136 [0.9257421] [1.3680946]\n",
      "300 0.011502665 [0.9306053] [1.3505368]\n",
      "320 0.010045326 [0.93515] [1.3341286]\n",
      "340 0.008772637 [0.93939716] [1.3187953]\n",
      "360 0.0076612225 [0.94336605] [1.3044664]\n",
      "380 0.006690615 [0.94707507] [1.2910757]\n",
      "400 0.0058429805 [0.95054114] [1.2785622]\n",
      "420 0.005102728 [0.9537802] [1.2668681]\n",
      "440 0.0044562286 [0.9568072] [1.2559395]\n",
      "460 0.0038916655 [0.959636] [1.245727]\n",
      "480 0.003398622 [0.9622794] [1.2361833]\n",
      "500 0.0029680403 [0.96474975] [1.2272645]\n",
      "520 0.002592024 [0.9670583] [1.21893]\n",
      "540 0.0022636151 [0.96921563] [1.211141]\n",
      "560 0.001976837 [0.97123176] [1.2038623]\n",
      "580 0.0017263964 [0.9731158] [1.1970603]\n",
      "600 0.0015076699 [0.97487646] [1.190704]\n",
      "620 0.0013166697 [0.9765218] [1.1847638]\n",
      "640 0.0011498432 [0.9780594] [1.1792123]\n",
      "660 0.0010041714 [0.97949636] [1.1740246]\n",
      "680 0.0008769583 [0.9808391] [1.1691769]\n",
      "700 0.0007658561 [0.98209393] [1.1646464]\n",
      "720 0.00066882605 [0.9832666] [1.1604128]\n",
      "740 0.0005840902 [0.9843624] [1.1564561]\n",
      "760 0.00051009026 [0.98538667] [1.1527588]\n",
      "780 0.00044547115 [0.98634356] [1.1493038]\n",
      "800 0.00038902927 [0.98723793] [1.1460748]\n",
      "820 0.00033974135 [0.98807377] [1.1430573]\n",
      "840 0.00029669408 [0.98885494] [1.1402371]\n",
      "860 0.00025910808 [0.98958486] [1.1376021]\n",
      "880 0.00022627917 [0.990267] [1.1351395]\n",
      "900 0.00019761387 [0.99090433] [1.1328381]\n",
      "920 0.00017258152 [0.99149996] [1.1306878]\n",
      "940 0.00015071302 [0.9920566] [1.128678]\n",
      "960 0.00013162055 [0.99257684] [1.1267998]\n",
      "980 0.00011494492 [0.993063] [1.1250447]\n",
      "1000 0.000100380996 [0.99351734] [1.1234045]\n",
      "1020 8.766424e-05 [0.99394184] [1.1218717]\n",
      "1040 7.655406e-05 [0.9943387] [1.1204388]\n",
      "1060 6.685555e-05 [0.9947095] [1.1191001]\n",
      "1080 5.8384157e-05 [0.995056] [1.1178492]\n",
      "1100 5.098888e-05 [0.9953798] [1.1166803]\n",
      "1120 4.4528617e-05 [0.9956824] [1.1155878]\n",
      "1140 3.8886308e-05 [0.9959652] [1.1145669]\n",
      "1160 3.3960856e-05 [0.9962294] [1.113613]\n",
      "1180 2.965744e-05 [0.9964763] [1.1127217]\n",
      "1200 2.5900168e-05 [0.996707] [1.1118885]\n",
      "1220 2.2620423e-05 [0.99692273] [1.11111]\n",
      "1240 1.9753696e-05 [0.9971243] [1.1103823]\n",
      "1260 1.7249546e-05 [0.99731266] [1.109702]\n",
      "1280 1.50637015e-05 [0.9974887] [1.1090666]\n",
      "1300 1.3155967e-05 [0.9976531] [1.1084728]\n",
      "1320 1.1489632e-05 [0.99780685] [1.107918]\n",
      "1340 1.0034004e-05 [0.9979505] [1.1073993]\n",
      "1360 8.762612e-06 [0.99808466] [1.1069148]\n",
      "1380 7.652388e-06 [0.99821013] [1.1064619]\n",
      "1400 6.6825946e-06 [0.9983274] [1.1060387]\n",
      "1420 5.836257e-06 [0.9984369] [1.1056432]\n",
      "1440 5.0963827e-06 [0.99853927] [1.1052735]\n",
      "1460 4.450458e-06 [0.998635] [1.1049279]\n",
      "1480 3.886503e-06 [0.99872446] [1.1046052]\n",
      "1500 3.3939596e-06 [0.99880797] [1.1043036]\n",
      "1520 2.9644377e-06 [0.998886] [1.1040218]\n",
      "1540 2.5883005e-06 [0.998959] [1.1037583]\n",
      "1560 2.2605823e-06 [0.99902713] [1.1035122]\n",
      "1580 1.974136e-06 [0.9990909] [1.1032821]\n",
      "1600 1.724228e-06 [0.9991504] [1.1030672]\n",
      "1620 1.5058007e-06 [0.999206] [1.1028662]\n",
      "1640 1.3146504e-06 [0.99925804] [1.1026785]\n",
      "1660 1.1485196e-06 [0.9993066] [1.1025033]\n",
      "1680 1.0029046e-06 [0.99935204] [1.1023393]\n",
      "1700 8.758507e-07 [0.9993945] [1.1021862]\n",
      "1720 7.648092e-07 [0.99943405] [1.1020429]\n",
      "1740 6.680234e-07 [0.9994712] [1.101909]\n",
      "1760 5.8333785e-07 [0.9995058] [1.101784]\n",
      "1780 5.0947835e-07 [0.9995382] [1.1016672]\n",
      "1800 4.448817e-07 [0.99956846] [1.1015581]\n",
      "1820 3.885285e-07 [0.99959666] [1.101456]\n",
      "1840 3.393252e-07 [0.999623] [1.1013608]\n",
      "1860 2.964704e-07 [0.9996477] [1.1012717]\n",
      "1880 2.5899345e-07 [0.9996708] [1.1011885]\n",
      "1900 2.2608579e-07 [0.9996924] [1.1011106]\n",
      "1920 1.9740833e-07 [0.99971247] [1.1010377]\n",
      "1940 1.7238845e-07 [0.9997313] [1.1009698]\n",
      "1960 1.5065015e-07 [0.9997489] [1.1009064]\n",
      "1980 1.3152248e-07 [0.99976534] [1.1008471]\n",
      "2000 1.1488711e-07 [0.9997807] [1.1007916]\n",
      "[6.099695]\n",
      "[3.6002436]\n",
      "[2.6004627 4.600024 ]\n"
     ]
    }
   ],
   "source": [
    "hypothesis = X * W + b    \n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "train = optimizer.minimize(cost) \n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(2001) :\n",
    "    cost_val, W_val, b_val, _ = sess.run([cost, W, b, train],\n",
    "            feed_dict = {X: [1,2,3,4,5], \n",
    "                         Y: [2.1, 3.1, 4.1, 5.1, 6.1]})\n",
    "    if step % 20 == 0:\n",
    "        print(step, cost_val, W_val, b_val)\n",
    "#테스트\n",
    "print(sess.run(hypothesis, feed_dict={X: [5]}))\n",
    "print(sess.run(hypothesis, feed_dict={X: [2.5]}))\n",
    "print(sess.run(hypothesis, feed_dict={X: [1.5, 3.5]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
